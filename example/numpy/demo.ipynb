{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of MXNet-NumPy Module\n",
    "\n",
    "## Namespaces for Imperative Programming\n",
    "- `mxnet.numpy`: Regular NumPy operators\n",
    "- `mxnet.numpy.random`: NumPy random operators\n",
    "- `mxnet.numpy.linalg`: NumPy linear algebra operators\n",
    "- `mxnet.numpy_extension`: Operators implemented in MXNet that do not exist in the official NumPy and some utils (e.g. context related functions).\n",
    "\n",
    "## Operator Namespaces for Gluon\n",
    "`F` can be either `mxnet.ndarray` or `mxnet.symbol`. Note that `np` and `npe` are aliases of `numpy` and `numpy_extension`, respectively.\n",
    "- `F.np`: Regular NumPy operators\n",
    "- `F.np.random`: NumPy random operators\n",
    "- `F.np.linalg`: NumPy linear algebra operators\n",
    "- `F.npe`: Operators implemented in MXNet that do not exist in official NumPy\n",
    "\n",
    "## New `ndarray` and `symbol`\n",
    "`mxnet.numpy.ndarray` (visible to users) and `mxnet.symbol.numpy._Symbol` (not directly visible to users)\n",
    "- Same name as in the official NumPy package\n",
    "- Dispatch convience fluent method calls to MXNet Numpy operators\n",
    "- Override many convenience fluent methods that do not exist in the official NumPy ndarray\n",
    "- Make the behavior of built-in methods consistent with the official NumPy\n",
    "    - Indexing: `__getitem__` and `__setitem__`\n",
    "    - Many binary element-wise with broadcasting, not supported in `mxnet.symbol.Symbol`\n",
    "    \n",
    "## User Experience of Module Importing (In Progress)\n",
    "**Legacy**\n",
    "```python\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "```\n",
    "**Numpy**\n",
    "```python\n",
    "from mxnet import np, npe, gluon\n",
    "```\n",
    "\n",
    "    \n",
    "## MXNet NumPy in Action\n",
    "### Scalar and zero-size tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import numpy as np\n",
    "\n",
    "# create a scalar tensor\n",
    "x = np.array(3.14)\n",
    "print(x)  # x is actually an ndarray, but a scalar value will be printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = x.item()  # copy the element from the scalar tensor to a python scalar\n",
    "print('s = {}'.format(str(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scalar tensors with only one element 1.0\n",
    "y = np.ones(())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a zero-size tensor\n",
    "x = np.ones((5, 4, 0, 6))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the zero-size tensor\n",
    "y = np.transpose(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion between classic and numpy ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a classic MXNet NDArray\n",
    "x = mx.nd.random.uniform(shape=(2, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert classic NDArray type to mxnet.numpy.ndarray with zero-copy\n",
    "y = x.as_np_ndarray()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing y's content changes x's content too\n",
    "y[:] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mxnet.numpy.ndarray to classic NDArray with zero-copy\n",
    "z = y.as_classic_ndarray()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing z's content changes y's content too\n",
    "z[:] = 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a line between classic operators and numpy operators...\n",
    "- Numpy operators can only accept numpy `ndarray`s/`_Symbol`s as inputs\n",
    "- Classic operators can only accept classic `NDArray`s/`Symbol`s as inputs\n",
    "- Explicit conversions must be performed if users want to leverage operators on both sides\n",
    "- The layer inheriting from `HybridBlock` must have the same type of outputs, i.e., either all classic `NDArray`s or all numpy `ndarray`s, before hybridization\n",
    "\n",
    "#### Imperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mx.nd.ones((2, 3))  # create a classic NDArray\n",
    "print(a)\n",
    "out = np.sum(a)  # feeding it to a numpy operator would result in failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.as_np_ndarray()  # convert `a` to a numpy ndarray sharing the same data memory\n",
    "print(b)\n",
    "out = np.sum(b)  # feed the numpy ndarray to a numpy operator\n",
    "print('np.sum(b) =', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mx.nd.sum(b)  # feeding `b` to a classic operator would reuslt in failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.as_classic_ndarray()  # convert `b` to a classic ndarray\n",
    "out = mx.nd.sum(c)  # feed the classic ndarray to a classic operator\n",
    "print('mx.nd.sum(c) =', str(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "class TestMultipleOutputs(gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x):\n",
    "        ret1 = F.sum(x)  # a classic operator produces a classic NDArray\n",
    "        ret2 = F.np.sum(x)  # a numpy operator produces a numpy NDArray\n",
    "        return ret1, ret2\n",
    "\n",
    "net = TestMultipleOutputs()\n",
    "net.hybridize()\n",
    "out = net(a)  # `a` is a classic NDArray and will cause an error on `F.np.sum` which is a numpy operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TestMultipleOutputs()  # redefine a net with no pre-built graph\n",
    "net.hybridize()\n",
    "out = net(b)  # `b` is a numpy ndarray and will cause an error on `F.sum` which is a classic operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMultipleOutputs2(gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x):  # x is known to be a numpy ndarray\n",
    "        ret1 = F.sum(x.as_classic_ndarray())  # a classic operator produces a classic NDArray\n",
    "        ret2 = F.np.sum()  # a numpy operator produces a numpy NDArray\n",
    "        return ret1, ret2  # two outputs of the layer with different types would result in failure in building the graph\n",
    "\n",
    "net = TestMultipleOutputs2()\n",
    "net.hybridize()\n",
    "out = net(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMultipleOutputs3(gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x):  # x is known to be a numpy ndarray\n",
    "        ret1 = F.sum(x.as_classic_ndarray())  # a classic operator produces a classic NDArray\n",
    "        ret2 = F.np.sum(x)  # a numpy operator produces a numpy NDArray\n",
    "        return ret1.as_np_ndarray(), ret2  # two outputs of the layer with different types would result in failure in building the graph\n",
    "\n",
    "net = TestMultipleOutputs3()\n",
    "net.hybridize()\n",
    "out = net(b)\n",
    "print('classic operator output: ', out[0])\n",
    "print('numpy operator output: ', out[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary element-wise operations with broadcasting in new and old symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestBinaryBroadcast(gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x1, x2):\n",
    "        print(\"x1 type in hybrid_forward:\", str(type(x1)))\n",
    "        print(\"x2 type in hybrid_forward:\", str(type(x2)))\n",
    "        return x1 + x2\n",
    "\n",
    "net = TestBinaryBroadcast()\n",
    "x1 = mx.nd.ones((2, 1))\n",
    "x2 = mx.nd.ones((1, 3))\n",
    "print('x1 input tensor type: ', str(type(x1)))\n",
    "print('x2 input tensor type: ', str(type(x2)))\n",
    "out = net(x1, x2)  # ok: imperative execution supports broadcasting\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.hybridize()  # mark the block for execution using a computational graph\n",
    "try:\n",
    "    out = net(x1, x2)  # error: old symbol `+` operation does not support broadcasting\n",
    "    assert False  # should not reach here\n",
    "except mx.MXNetError:\n",
    "    print(\"ERROR: cannot perform broadcast add for two symbols of type mx.sym.Symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TestBinaryBroadcast()  # redefine a net to clear the pre-built graph cache\n",
    "net.hybridize()\n",
    "\n",
    "x1 = x1.as_np_ndarray()  # convert x1 to np.ndarray\n",
    "x2 = x2.as_np_ndarray()  # convert x2 to np.ndarray\n",
    "print('x1 input tensor type: ', str(type(x1)))\n",
    "print('x2 input tensor type: ', str(type(x2)))\n",
    "out = net(x1, x2)  # ok: a graph is built with numpy symbols which supports broadcasting, because inputs are np.ndarray's, \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Linear Regression Model\n",
    "Let's consider a simple linear regression model as the following.\n",
    "Given dataset `{x, y}`, where `x`s represent input examples and `y`s represent observed data, find the parameters `w1` and `w2` for the following model.\n",
    "```\n",
    "y_pred = np.dot(np.maximum(np.dot(x, w1), 0), w2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, np\n",
    "\n",
    "\n",
    "@np.use_np_compat\n",
    "class LinearRegression(gluon.HybridBlock):\n",
    "    def __init__(self, num_input_dim=1000, num_hidden_dim=100, num_output_dim=10):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.w1 = self.params.get('w1', shape=(num_input_dim, num_hidden_dim),\n",
    "                                      allow_deferred_init=True)\n",
    "            self.w2 = self.params.get('w2', shape=(num_hidden_dim, num_output_dim),\n",
    "                                      allow_deferred_init=True)\n",
    "\n",
    "    def hybrid_forward(self, F, x, w1, w2):\n",
    "        h = x.dot(w1)  # equivalent to F.np.dot(x, w1)\n",
    "        h_relu = F.npe.relu(h)  # equivalent to F.relu(h) but generating np.ndarray\n",
    "        y_pred = h_relu.dot(w2)  # equivalent to F.np.dot(h_relu, w2)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class TotalLoss(gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, pred, label):\n",
    "        return ((pred - label) ** 2).sum()  # equivalent to F.np.sum(F.np.square(pred - label))\n",
    "\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.initialize(mx.init.Normal())\n",
    "regressor.hybridize()\n",
    "\n",
    "# Create random input and output data\n",
    "x = mx.nd.random.normal(shape=(64, 1000)).as_np_ndarray()  # x is of type mxnet.numpy.ndarray\n",
    "y = mx.nd.random.normal(shape=(64, 10)).as_np_ndarray()  # y is of type mxnet.numpy.ndarray\n",
    "\n",
    "total_loss = TotalLoss()\n",
    "trainer = gluon.Trainer(regressor.collect_params(),\n",
    "                        'sgd',\n",
    "                        {'learning_rate': 1e-3, 'momentum': 0.9, 'allow_np': True})\n",
    "\n",
    "for t in range(50):\n",
    "    with autograd.record():\n",
    "        output = regressor(x)  # output is a type of np.ndarray because np.dot is the last op in the network\n",
    "        loss = total_loss(output, y)  # loss is a scalar np.ndarray\n",
    "    loss.backward()\n",
    "    print(t, loss)  # note that loss.asnumpy() is called\n",
    "    trainer.step(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
